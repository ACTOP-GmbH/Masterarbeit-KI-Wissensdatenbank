\pagebreak
\section{Einleitung}
Unternehmen verfügen über eine Fülle von Dokumenten und Daten, die auf Plattformen wie Microsoft SharePoint, OneDrive oder in Datenbanken abgelegt sind.
Mitarbeiter stehen oft vor der Herausforderung, benötigte Informationen aus dieser Menge an unstrukturiertem Wissen schnell zu extrahieren.
KI-basierte Chatbots versprechen hier Abhilfe, indem sie, anhand eines trainierten Datenmodells, in natürlicher Sprache Fragen beantworten können.
Allerdings sind viele frei verfügbare Chatbot-Lösungen (etwa große Sprachmodelle à la ChatGPT) für den direkten Einsatz auf interne Firmendaten nicht geeignet, da die Eingabedaten an externe Server übertragen werden und somit Datenschutzrisiken entstehen\href{https://punctuations.ai/ai-agents-workflows/your-private-gpt-the-case-for-secure-on-premise-llms/#:~:text=pharmaceutical%20companies%2C%20manufacturers%2C%20government%20contractors,keeping%20AI%20close%20to%20home}{punctuations.ai}.
Die Entwicklung eines \textit{datenschutzkonformen Chatbots} erfordert daher einen Ansatz, bei dem vertrauliche Dokumente im eigenen Verantwortungsbereich verbleiben (On-Premises-Betrieb) und dennoch die Leistungsfähigkeit moderner KI genutzt wird.


Diese Masterarbeit untersucht die Entwicklung eines RAG-gestützten Chatbots (Retrieval-Augmented Generation), der es ermöglicht, interne Dokumente automatisiert auszulesen und zur Beantwortung von Benutzeranfragen heranzuziehen.
Im Fokus stehen dabei Datenschutz und Machbarkeit: Das System soll ausschließlich innerhalb der unternehmenseigenen IT-Infrastruktur operieren, sodass keine sensiblen Inhalte nach außen gelangen.
Gleichzeitig soll der Chatbot die Vorteile von \textit{Large Language Models} (LLMs) nutzen, um den Nutzern präzise und kontextrelevante Antworten in einem Chat-Interface bereitzustellen.
Dokumente aus SharePoint, OneDrive und optional weiteren Quellen (z.B.\ firmeneigene Datenbanken) werden dafür als Wissensbasis eingebunden.


Die Motivation für diese Arbeit ergibt sich aus dem Bedarf, internes Wissen schneller zugänglich zu machen, ohne gegen Datenschutzrichtlinien zu verstoßen.
Im Rahmen der Arbeit werden zunächst die Problemstellung und Anforderungen analysiert, gefolgt von theoretischen Grundlagen zu LLMs, RAG und Datenschutz.
Darauf aufbauend werden die technische Umsetzung und das Vorgehen bei der Implementierung beschrieben.
Abschließend werden die erzielten Ergebnisse präsentiert und in der Zusammenfassung Schlussfolgerungen sowie ein Ausblick gegeben.

Es ergeben sich folgende Forschungsfragen, die im Verlauf der Arbeit beantwortet werden sollen:

\begin{enumerate}
    \item Wie kann ein RAG-Chatbot für firmeninterne Wissensdatenbanken technisch umgesetzt werden?

    \item Welche Mehrwerte bietet ein RAG-gestützter Chatbot im Vergleich zu klassischen Suchsystemen?

    \item Welche Faktoren beeinflussen die Qualität und Akzeptanz eines RAG-Chatbots im Unternehmenskontext?

    \item Welche Herausforderungen ergeben sich bei Datenschutz, Sicherheit und Integration in bestehende Systeme?

\end{enumerate}


Daraus leiten sich die Ziele der Arbeit ab:

\begin{itemize}
    \item Entwicklung eines Prototyps für einen RAG-Chatbot, der interne Dokumente aus SharePoint und OneDrive nutzt.
    \item Evaluation der Antwortqualität und Benutzerfreundlichkeit des Chatbots.
    \item Analyse der Datenschutzaspekte und Implementierung geeigneter Sicherheitsmaßnahmen.
    \item Identifikation von Herausforderungen und Best Practices für den Einsatz von RAG-Chatbots in Unternehmen.
    \item Wie ist der Entwicklungsaufwand für ein Kleinunternehmen ohne externe Cloud-Dienste realisierbar?
\end{itemize}

