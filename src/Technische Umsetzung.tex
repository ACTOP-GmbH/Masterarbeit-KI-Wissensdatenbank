\section{Technische Umsetzung}\label{sec:technische-umsetzung}
Die technische Umsetzung des datenschutzkonformen RAG-Chatbots gliedert sich in mehrere
komponenten, die zusammenarbeiten, um die Anforderungen zu erfüllen.

\subsection{Notwendige Architekturkomponenten}
Die Architektur des RAG-Chatbots umfasst folgende Hauptkomponenten:
\begin{itemize}
    \item \textbf{Dokumenten-Connectoren:} Schnittstellen, um Dokumente aus SharePoint, OneDrive und anderen Quellen zu extrahieren.
    \item \textbf{Dokumenten-Parser:} Tools zur Textextraktion und -bereinigung aus verschiedenen Dateiformaten (PDF, Word, E-Mail etc.).
    \item \textbf{Chunking-Modul:} Logik zur Aufteilung langer Dokumente in kleinere, semantisch sinnvolle Abschnitte.
    \item \textbf{Embedding-Modell:} Vortrainiertes Modell (z.B. Sentence-BERT), das Textabschnitte in Vektor-Repräsentationen umwandelt.
    \item \textbf{Vektordatenbank:} Speicherung und effiziente Suche der Embeddings (z.B. FAISS, Milvus).
    \item \textbf{Retrieval-Modul:} Komponente, die bei Nutzeranfragen relevante Dokumentenabschnitte aus der Vektordatenbank abruft.
    \item \textbf{LLM-Integration:} Anbindung eines Large Language Models (z.B. GPT-4, LLaMA) zur Generierung der Antworten basierend auf den abgerufenen Kontextinformationen.
    \item \textbf{Chat-Interface:} Frontend-Komponente für die Interaktion mit den Nutzern (z.B. Web-App, Teams-Bot).
    \item \textbf{Sicherheits- und Datenschutzmodule:} Mechanismen zur Gewährleistung des On-Premises-Betriebs, Zugriffskontrolle und Datenminimierung.
\end{itemize}

\subsection{Prototypische Implementierung zur Evaluierung der technischen Machbarkeit}

\subsubsection{CPU Testing und Auswahl der LLM-Modelle}
Um die technische Machbarkeit eines On-Premises RAG-Chatbots zu evaluieren, wurde ein Prototyp entwickelt.
Zunächst wurden verschiedene LLM-Modelle hinsichtlich ihrer Leistungsfähigkeit auf CPU-Hardware überprüft.
Modelle wie GPT-4All, LLaMA 2 und Mistral wurden getestet, um festzustellen, welche Modelle akzeptable Antwortzeiten und Genauigkeit bieten.
Die Tests zeigten, dass selbst kleinere Modelle wie LLaMA 2 7B auf modernen CPUs lauffähig sind, jedoch mit längeren Antwortzeiten im Vergleich zu GPU-beschleunigten Setups.
Auf dem Windowsserver dauerte die Generierung einer Antwort auf ein simples \("\)Hallo\("\) ca. 127 Sekunden.
Dies verdeutlicht die Herausforderungen bei der Nutzung von LLMs ohne spezialisierte Hardware.
\par
Viele der Herausforderungen bei der Nutzung von LLMs auf CPU-Hardware ergeben sich aus deren Architektur.
Transformer-basierte Modelle sind sehr rechenintensiv, da sie viele Matrixmultiplikationen durchführen müssen.
Ohne die parallele Verarbeitungskapazität von GPUs verlängert sich die Inferenzzeit erheblich.
Auch die Installation und der Betrieb solcher Modelle auf dedizierten CPU-Servern erfordern sorgfältige Optimierungen, um die Leistung zu maximieren.
Dadurch ist aber der Windows-Server sehr schnell damit beschäftigt sich um die Berechnungen zu kümmern.
Bei parallel laufenden Prozessen, wie dem Vektor-Suchdienst und dem Chat-Interface, kommt es schnell zu Engpässen.
Hier sollen später immerhin im Worst-Case bis zu 20 Nutzer gleichzeitig bedient werden.
\par
Damit schied der Gedanke aus, den Chatbot ohne GPU-Unterstützung zu betreiben.
\subsubsection{GPU Testing und Auswahl der LLM-Modelle}
Um dies zu gewährleisten bedurfte es einer sinnvollen GPU-Unterstützung.
Die notwendige Hardware für die meisten LLMs ist sehr unterschiedlich.
Während einige Modelle wie GPT-4All mit 4-8 GB VRAM auskommen, benötigen größere Modelle wie LLaMA 2 70B mehrere High-End-GPUs mit jeweils 24 GB VRAM.
Eine akzeptable Leistung und Antwortzeit auf einem einzelnen GPU-System bieten Modelle wie LLaMA 2 7B oder Mistral 7B.
Neuere Modelle werden immer besser darin, mit weniger Ressourcen auszukommen, was die Einstiegshürde für On-Premises-Lösungen senkt.
\par
Es wurde sich dazu entschieden einen Laptop mit einer RTX-5070TI Grafikkarte zu verwenden.
Diese hat 12 GB VRAM und ist damit in der Lage, Modelle wie LLaMA 2 7B oder Mistral 7B effizient auszuführen.
Dieser Laptop besitzt zudem 32 GB RAM mit 6400 MT/s und einen Intel Core Ultra I9 275HX Prozessor mit 24 Kernen.
Das System ist ein DDR5 System, die dadurch hohe Arbeitsspeicherbandbreiten ermöglicht, welche für die Verarbeitung großer Modelle von Vorteil sind.
\par
Trotz dessen, dass dies grundsätzlich ein Laptop ist, ist dennoch ein vollwertiger Desktop-Prozessor in diesem Modell verbaut mit einem Netzteil von 300 Watt.
Die hohe Energeeffizienz der 5070TI ermöglicht es, dass diese Grafikkarte auch in einem Laptop betrieben werden kann und kaum Mehrwert ab etwa 100 bis 150 Watt bringt.
Mit einem Preis von €2.489,53 ist dies eine verhältnismäßig günstige Lösung, um einen On-Premises RAG-Chatbot zu betreiben.
Dies inkludiert zudem 2 TB NVMe Speicher, welcher für die Vektordatenbank und die Dokumentenspeicherung genutzt werden kann.
Die Notwendigkeit eines Laptops ergibt sich daraus, dass nicht mit Online-Diensten gearbeitet werden soll.
Ein Desktop-PC mit vergleichbarer Leistung wäre zwar günstiger, passt jedoch nicht in die bestehende IT-Infrastruktur des Unternehmens.
Zudem ermöglicht dies potentiell die zukünftige Nutzung von Endgeräten als Ressourcenpool für die GPU-Berechnungen.
Dies wäre also der Edge-Computing Ansatz, welcher in Zukunft immer relevanter wird.



